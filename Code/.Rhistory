use.names = TRUE,
fill = TRUE
)
# Show the final results
print(paste("Total pollutants with CAS number:", nrow(final_results)))
GB <- read.xlsx("C:/Users/owner/OneDrive - huji.ac.il/PhD/reports/GreenBasine/CW_nabulus_raw.xlsx")
gb_p <- GB %>%
select(1, 4, 21:ncol(.)) %>%
mutate(across(3:ncol(.), ~as.numeric(.) %>% replace_na(0))) %>% # warning: NAs introduced by coercio - needs to be checked
filter(rowSums(across(3:ncol(.))) > 0) %>%
pivot_longer(cols = 3:length(.), names_to = "PREFERRED_NAME", values_to = "Concentration") %>%
pivot_wider(names_from = c(1,2), values_from = Concentration)
# Loading data
NUKA <- read.fst("NUKA.fst") %>%
rename("CASRN" = CAS)# CAS from NUKA
DSSTox <- read.fst("DSSTox.fst") # CAS from DSSTox
Internal_data <- gb_p # The user's data (in this case- the GreenBasine project)
p_vector <- Internal_data[[1]] # Create a vector of compounds from the user's data for CAS search
# Convert to data.table for more efficient operations
setDT(NUKA)
setDT(DSSTox)
setDT(Internal_data)
# First search - NUKA (exact search)
internal_list1 <- NUKA[NUKA$PREFERRED_NAME %in% p_vector, ]
p_vector_found <- internal_list1$PREFERRED_NAME # Creating a vector of all p found
unfound <- p_vector[!p_vector %in% p_vector_found] # Saving the p that weren't found in NUKA for further search in DSSTox
#information about first stage- how many found and not found in exact search from NUKA
print(paste("Number of compounds found in NUKA:", length(p_vector_found)))
print(paste("Number of compounds not found in NUKA:", length(unfound)))
# Create a data.table for unfounded pollutants for easier manipulation
unfound_dt <- data.table(PREFERRED_NAME = unfound)
# Second search - DSSTox (fuzzy)
# Interactive fuzzy matching function with confirmation for uncertain matches
fuzzy_match_interactive <- function(source_names, target_dt, match_col, threshold = 0.05, confirm_threshold = 0.01) {
# Create a result data table
result <- data.table(
source_name = source_names,
matched_name = NA_character_,
distance = NA_real_,
confirmed = FALSE
)
# Process each source name row by row
for (i in 1:length(source_names)) {
name <- source_names[i]
# Skip NA values in source
if (is.na(name)) {
next
}
# Calculate distances to all target names (excluding NA targets)
valid_targets <- target_dt[[match_col]][!is.na(target_dt[[match_col]])]
# Handle case where there are no valid targets
if (length(valid_targets) == 0) {
next
}
distances <- stringdist(name, valid_targets, method = "jw")
# Find the best match if any valid distances exist
if (length(distances) > 0 && !all(is.na(distances))) {
min_dist <- min(distances, na.rm = TRUE)
best_idx <- which.min(distances)
best_match <- valid_targets[best_idx]
match_quality <- round((1 - min_dist) * 100, 1)
if (!is.na(min_dist) && min_dist <= threshold) {
# Get CASRN number for the matched compound
casrn_number <- target_dt[get(match_col) == best_match, CASRN]
casrn_display <- if(length(casrn_number) > 0 && !is.na(casrn_number[1])) casrn_number[1] else "Not available"
# Auto-accept 100% matches, show message box for matches >= 95%
if (match_quality == 100) {
# Auto-accept perfect matches
confirmed <- TRUE
} else if (match_quality >= threshold) {
# Show message box for high confidence matches (95% and above, but not 100%)
message_text <- paste0(
"Match found for compound matching:\n\n",
"Source compound: ", name, "\n",
"Matched compound: ", best_match, "\n",
"CASRN number: ", casrn_display, "\n",
"Match confidence: ", match_quality, "%\n\n",
"Do you want to accept this match?"
)
# Display message box with consistent format
answer <- tcltk::tkmessageBox(
title = paste0("Compound Match (", match_quality, "% confidence)"),
message = message_text,
icon = "question",
type = "yesno"
)
confirmed <- as.character(answer) == "yes"
} else {
# For matches below 95%, don't show message box (reject automatically)
confirmed <- FALSE
}
if (confirmed) {
result[i, `:=`(
matched_name = best_match,
distance = min_dist,
confirmed = TRUE
)]
}
}
}
}
return(result)
}
# Run the interactive matching
matches <- fuzzy_match_interactive(
unfound,
DSSTox,
"PREFERRED_NAME",
threshold = 0.1,      # Maximum allowed distance
confirm_threshold = 0.01  # Auto-accept if distance <= 0.01
)
# Count confirmed matches
match_count <- sum(matches$confirmed, na.rm = TRUE)
print(paste("Number of confirmed fuzzy matches:", match_count))
# Create final result data.table with CASRN numbers
# First, get the CASRN numbers for exact matches from NUKA
exact_matches <- NUKA[PREFERRED_NAME %in% p_vector_found, .(PREFERRED_NAME, CASRN)]
# Then get CASRN numbers for fuzzy matches from DSSTox
fuzzy_confirmed <- matches[confirmed == TRUE]
fuzzy_matches <- DSSTox[DSSTox$PREFERRED_NAME %in% fuzzy_confirmed$matched_name,
.(PREFERRED_NAME, CASRN)]
# Map the original names to the matched DSSTox names to get CASRN numbers
fuzzy_results <- merge(
fuzzy_confirmed[, .(source_name, matched_name)],
fuzzy_matches,
by.x = "matched_name",
by.y = "PREFERRED_NAME",
all.x = TRUE
)
# Rename columns for consistency
setnames(fuzzy_results, "source_name", "PREFERRED_NAME")
# Combine exact and fuzzy matches
final_results <- rbindlist(
list(
exact_matches,
fuzzy_results[, .(PREFERRED_NAME, CASRN)]
),
use.names = TRUE,
fill = TRUE
)
# Show the final results
print(paste("Total pollutants with CASRN numbers:", nrow(final_results)))
# Count unexact matches (matches accepted through message box, excluding 100% matches)
unexact_matches <- sum(matches$confirmed == TRUE & matches$distance > 0, na.rm = TRUE)
print(paste("Number of unexact matches accepted by user:", unexact_matches))
print(paste("Number of compounds found in NUKA:", length(p_vector_found)))
print(paste("Number of compounds not found in NUKA:", length(unfound)))
# Count confirmed matches
match_count <- sum(matches$confirmed, na.rm = TRUE)
print(paste("Number of confirmed fuzzy matches (exact match from DSSTox):", match_count))
# Count unexact matches (matches accepted through message box, excluding 100% matches)
unexact_matches <- sum(matches$confirmed == TRUE & matches$distance > 0, na.rm = TRUE)
print(paste("Number of unexact matches accepted by user:", unexact_matches))
#information about first stage- how many found and not found in exact search from NUKA
print(paste("Number of compounds found in NUKA:", length(p_vector_found), "out of", length(p_vector)))
#search CARSN result:
#information about first stage- how many found and not found in exact search from NUKA
print(paste("Number of compounds found in NUKA:", length(p_vector_found), "out of", length(p_vector)))
# Count confirmed matches
match_count <- sum(matches$confirmed, na.rm = TRUE)
print(paste("Number of confirmed fuzzy matches (exact match from DSSTox):", match_count))
# Count unexact matches (matches accepted through message box, excluding 100% matches)
unexact_matches <- sum(matches$confirmed == TRUE & matches$distance > 0, na.rm = TRUE)
print(paste("Number of unexact matches accepted by user:", unexact_matches))
print(paste("Total pollutants with CASRN numbers:", nrow(final_results)))
print(paste("Total pollutants with CASRN numbers:", nrow(final_results),"out of", length(p_vector)))
#search CARSN result:
percentage_found <- round((nrow(final_results) * 100 / length(p_vector)), 1)
print(paste("Total pollutants with CASRN numbers:", nrow(final_results), "out of", length(p_vector), "(", percentage_found, "%)"))
print(paste("Total pollutants with CASRN numbers:", nrow(final_results), "out of", length(p_vector), "(",percentage_found,"%)"))
View(final_results)
p_casrn <- final_results$CASRN
str(p_casrn)
is.vector(p_casrn)
# Create a vector of all CASRN numbers from your final results
casrn_vector <- final_results$CASRN[!is.na(final_results$CASRN)]
# Remove any empty strings or invalid entries
casrn_vector <- casrn_vector[casrn_vector != "" & !is.na(casrn_vector)]
print(paste("Number of CASRN numbers to search:", length(casrn_vector)))
# Search for algae EC50 toxicity data using ECOTOXr
# Note: This may take some time depending on the number of compounds
algae_toxicity_data <- search_ecotox(
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",  # Focus on algae
effect = NULL,   # Get all effect types
endpoint = "EC50", # Focus specifically on EC50 values
duration = NULL, # Get all durations
download_date = Sys.Date()
)
# Search for algae EC50 toxicity data using ECOTOXr
# Note: This may take some time depending on the number of compounds
algae_toxicity_data <- search_ecotox(
search = "toxicity",
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",  # Focus on algae
effect = NULL,   # Get all effect types
endpoint = "EC50", # Focus specifically on EC50 values
duration = NULL, # Get all durations
download_date = Sys.Date()
)
algae_toxicity_data <- search_ecotox(
search = "toxicity",  # REQUIRED argument
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",         # Focus on algae
effect = NULL,          # Get all effect types
endpoint = "EC50",      # Focus specifically on EC50 values
duration = NULL,        # Get all durations
download_date = Sys.Date()
)
algae_toxicity_data <- search_ecotox(
search = "toxicity",
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",
effect = NULL,
endpoint = "EC50",
duration = NULL,
download_date = Sys.Date(),
version = "2025-03-13"  # Explicitly use this version
)
# Break the vector into chunks of 50 (or another small number)
casrn_chunks <- split(casrn_vector, ceiling(seq_along(casrn_vector) / 5))
# Safe wrapper to catch errors without stopping the loop
safe_search <- purrr::safely(function(chunk) {
search_ecotox(
search = "toxicity",
chemical_name = NULL,
cas_number = chunk,
species = NULL,
taxa = "Algae",
effect = NULL,
endpoint = "EC50",
duration = NULL,
download_date = Sys.Date(),
version = "2025-03-13"
)
})
# Run search over chunks
results_list <- map(casrn_chunks, safe_search)
results_list
# Separate successful and failed results
successes <- map(results_list, "result")
failures <- map(results_list, "error")
# Combine successful data frames
algae_toxicity_data <- do.call(rbind, successes)
algae_toxicity_data
View(successes)
View(failures)
# Safe wrapper to catch errors without stopping the loop
safe_search <- purrr::safely(function(chunk) {
search_ecotox(
search = "toxicity",
chemical_name = NULL,
cas_number = chunk,
species = NULL,
taxa = "Algae",
effect = NULL,
endpoint = "EC50",
duration = NULL,
download_date = Sys.Date(),
version = "2025-03-13"
)
})
safe_search
View(results_list)
search_ecotox(
search = "toxicity",
chemical_name = NULL,
cas_number = chunk,
species = NULL,
taxa = "Algae",
effect = NULL,
endpoint = "EC50",
duration = NULL,
download_date = Sys.Date(),
version = "2025-03-13"
)
casrn_vector
# Remove any empty strings or invalid entries
casrn_vector <- as.numeric(casrn_vector[casrn_vector != "" & !is.na(casrn_vector)])
casrn_vector
# Remove any empty strings or invalid entries
casrn_vector <- casrn_vector[casrn_vector != "" & !is.na(casrn_vector)] %>%
as.numeric(.)
casrn_vector
ECOTOXr::get_ecotox_sqlite_file()
ECOTOXr::clear_ecotox_cache()
algae_toxicity_data <- search_ecotox(
search = "toxicity",  # REQUIRED argument
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",         # Focus on algae
effect = NULL,          # Get all effect types
endpoint = "EC50",      # Focus specifically on EC50 values
duration = NULL,        # Get all durations
download_date = Sys.Date()
)
is.character(casrn_vector)
# Create a vector of all CASRN numbers from your final results
casrn_vector <- final_results$CASRN[!is.na(final_results$CASRN)]
is.character(casrn_vector)
# Remove any empty strings or invalid entries
casrn_vector <- casrn_vector[casrn_vector != "" & !is.na(casrn_vector)]
print(paste("Number of CASRN numbers to search:", length(casrn_vector)))
algae_toxicity_data <- search_ecotox(
search = "toxicity",  # REQUIRED argument
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",         # Focus on algae
effect = NULL,          # Get all effect types
endpoint = "EC50",      # Focus specifically on EC50 values
duration = NULL,        # Get all durations
download_date = Sys.Date()
)
# OPTIONAL: clean and deduplicate CASRNs first
casrn_vector <- unique(casrn_vector[casrn_vector != "" & !is.na(casrn_vector)])
casrn_vector
# Get path to DB (optional but helps avoid ambiguity)
db_path <- get_ecotox_sqlite_file()
# Split CASRNs into chunks of 20
casrn_chunks <- split(casrn_vector, ceiling(seq_along(casrn_vector) / 5))
# Safe wrapper
safe_search <- safely(function(chunk) {
search_ecotox(
search = "toxicity",
cas_number = chunk,
taxa = "Algae",
endpoint = "EC50",
download_date = Sys.Date(),
path = db_path  # use explicit path to the SQLite file
)
})
safe_search
# Run the safe search
results_list <- map(casrn_chunks, safe_search)
results_list
# Extract good results
successful_results <- map(results_list, "result")
successful_results
# Combine successful results
algae_toxicity_data <- bind_rows(successful_results)
algae_toxicity_data
View(algae_toxicity_data)
# Optional: identify failed chunks
failed_chunks <- which(map_lgl(results_list, ~ !is.null(.x$error)))
failed_chunks
# Print which chunks failed
if (length(failed_chunks) > 0) {
message("Failed chunks at indices: ", paste(failed_chunks, collapse = ", "))
message("Problem CASRNs: ", paste(unlist(casrn_chunks[failed_chunks]), collapse = ", "))
}
list_ecotox_fields()
algae_toxicity_data <- search_ecotox(
chemical_name = NULL,
cas_number = casrn_vector,
species = NULL,
taxa = "Algae",  # Focus on algae
effect = NULL,   # Get all effect types
endpoint = NULL, # Get all endpoints (LC50, EC50, NOEC, etc.)
duration = NULL, # Get all durations
download_date = Sys.Date()
)
algae_toxicity_data <- search_ecotox(
search = list(
cas = casrn_vector,
taxa = "Algae",
endpoint = "EC50"
)
)
help(package = "ECOTOXr")
list_ecotox_fields()
write.fst(gb_p, "gb_p.fst")
library(openxlsx)
library(tidyr)
library(dplyr)
library(ggplot2)
library(scales)
library(ggthemes)
library(tidyverse)
library(extrafont)
library(ggpattern)
library(ggpubr)
library(ggpmisc)
library(hrbrthemes)
library(vegan)
library(permute)
library(lattice)
library(ggrepel)
library(gridExtra)
library(stringr)
library(rstatix)
library(dplyr)
library(cowplot)
library(ggbreak)
library(ggVennDiagram)
library(VennDiagram)
Sys.setlocale("LC_TIME", "English")
class_palette <- c("Industrial Chemicals" = "#798276", "PPCP" = "#95B9D8", "Pesticides" = "#E2CA6B")
estuary_palette <- c("Kishon" = "#7FC97F", "Alexander" = "#FDC086", "Lachish" = "#BEAED4")
Station_palette <- c("K1 Surface" = "#BEF0BE",
"K2 Surface" = "#77BB77",
"K2 Deep" = "#2F4A2F",
"K3 Surface" = "#429642",
"K4 Surface" = "#166916",
"A1 Surface" = "#FFE8D3",
"A3 Surface" = "#F3A255",
"A3 Deep" = "#6E4926",
"L3 Surface" = "#BEAED4",
"L3 Deep" = "#40394A",
"K2 Sediment" = "#7FC97F",
"A3 Sediment" = "#FDC086",
"L3 Sediment" = "#BEAED4")
theme_class <- theme(aspect.ratio = 0.4,
panel.grid.major = element_line(colour = "gray", linetype = "longdash"),
panel.grid.minor = element_line(colour = "gray", linetype = "longdash"),
panel.border = element_rect(fill = NA, color = "black", size = 0.5),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
strip.background = element_rect(fill = "white", color = "black", linewidth = 1.5, linetype = "solid"),
strip.text = element_text(size = 30, family = "Times New Roman"),
axis.title.y = element_text(size = 25, family = "Times New Roman"),
axis.title.x = element_blank(),
axis.text.y = element_text(size = 20, colour = "black", family = "Times New Roman"),
axis.text.x = element_text(size = 20, colour = "black", family = "Times New Roman"),
legend.text = element_text(size = 30, family = "Times New Roman"),
legend.key.size = unit(1, "cm"),
legend.title = element_blank(),
legend.position = "right",
legend.background = element_blank(),
legend.key = element_rect(fill = "white"))
#pollutants data
mm_w <- read.xlsx("p_data/mm_cal.xlsx", sheet = 5)
mm_s <- read.xlsx("p_data/mm_cal.xlsx", sheet = 6)
ja_a_w <- read.xlsx("p_data/Alexander_summer.xlsx", sheet = 5)
ja_a_s <- read.xlsx("p_data/Alexander_summer.xlsx", sheet = 6)
ja_l_k_s <- read.csv("p_data/JA_sediment_pollutants.csv") %>%
select(c(1:2,4:5,7:8,10:13)) %>%
mutate_at(vars(3:10), funs(.*1000))
reanalysis_a_w <- read.xlsx("p_data/reanalysis_alex.xlsx", sheet = 5)
reanalysis_a_s <- read.xlsx("p_data/reanalysis_alex.xlsx", sheet = 6)
sn_w <- read.xlsx("p_data/sn_cal.xlsx", sheet = 5)
sn_s <- read.xlsx("p_data/sn_cal.xlsx", sheet = 6)
#BGC DATA
bgc <- read.xlsx("bgc_data/bgc_data_new.xlsx")
#Contaminant list
p_list <- read.xlsx("contaminants_list.xlsx") %>%
select(-c(4:length(.)))
#write.xlsx(p_list, "results_2/p_list2.xlsx")
View(p_list)
w_p <- full_join(mm_w, ja_a_w) %>%
full_join(reanalysis_a_w)%>%
full_join(sn_w)
s_p <- full_join(mm_s, ja_a_s) %>%
full_join(reanalysis_a_s)%>%
full_join(sn_s) %>%
full_join(ja_l_k_s)
p_all <- full_join(w_p, s_p) %>%
mutate(across(3:length(.), ~replace_na(., 0))) %>%
select(-Classification)
meta <- left_join(p_list, p_all, by = "Contaminants") %>%
select(-c("Contaminants", "Classification")) %>% #leaves short names and prepare to bgc margin (removes class)
pivot_longer(cols = 2:length(.), names_to = "Label", values_to = "Concentration") %>%
pivot_wider(names_from = "Contaminant", values_from = "Concentration") %>%
left_join(bgc, by = "Label") %>%
mutate(Estuary = if_else(substr(Label, 1, 1) == "A", "Alexander",
if_else(substr(Label, 1, 1) == "K", "Kishon", "Lachish")),
Station = substr(Label, 1, 2),
Layer = if_else(substr(Label, 3, 3) == "S", "Surface",
if_else(substr(Label, 3, 3) == "D", "Deep", "Sediment")),
Medium = if_else(Layer == "Surface", "Water",
if_else(Layer == "Deep", "Water", "Sediment")),
Date1 = substr(Label, start = nchar(Label) -7,
stop = nchar(Label)),
DD = substr(Date1, 1, 2),
MM = substr(Date1, 3, 4),
YYYY = substr(Date1, 5, 8),
Date = as.Date(paste(YYYY, MM, DD, sep = "-"))) %>%
select(-Date1) %>%
relocate(c(317:324), .after = "Label") %>%
relocate(c(287:324), .after = "Date") %>%
filter(!Label == "L3D_20092022") #exclude Lachish's problomatic sample
#write.xlsx(meta, "results_2/metadata2.xlsx")
meta <- left_join(p_list, p_all, by = "Contaminants") %>%
select(-c("Contaminants", "Classification")) %>% #leaves short names and prepare to bgc margin (removes class)
pivot_longer(cols = 2:length(.), names_to = "Label", values_to = "Concentration") %>%
pivot_wider(names_from = "Contaminant", values_from = "Concentration") %>%
left_join(bgc, by = "Label") %>%
mutate(Estuary = if_else(substr(Label, 1, 1) == "A", "Alexander",
if_else(substr(Label, 1, 1) == "K", "Kishon", "Lachish")),
Station = substr(Label, 1, 2),
Layer = if_else(substr(Label, 3, 3) == "S", "Surface",
if_else(substr(Label, 3, 3) == "D", "Deep", "Sediment")),
Medium = if_else(Layer == "Surface", "Water",
if_else(Layer == "Deep", "Water", "Sediment")),
Date1 = substr(Label, start = nchar(Label) -7,
stop = nchar(Label)),
DD = substr(Date1, 1, 2),
MM = substr(Date1, 3, 4),
YYYY = substr(Date1, 5, 8),
Date = as.Date(paste(YYYY, MM, DD, sep = "-"))) %>%
select(-Date1) %>%
relocate(c(317:324), .after = "Label") %>%
relocate(c(287:324), .after = "Date") #%>%
